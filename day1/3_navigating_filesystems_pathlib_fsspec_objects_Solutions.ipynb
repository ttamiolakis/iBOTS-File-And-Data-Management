{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating the Filesystem\n",
    "\n",
    "Let's delve into the essential skills of navigating and managing files and directories, a fundamental aspect of handling experimental data in neuroscience research. We will explore various commands and techniques to efficiently organize and access your experimental data, ensuring seamless integration into your analysis workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Following Code to Get the Data for this Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "paths = [\n",
    "    \"data/exp1/joey_2021-05-01_001/spikes.npy\", \n",
    "    \"data/exp1/joey_2021-05-02_001/spikes.npy\", \n",
    "    \"data/exp1/joey_2021-05-02_001/lfps.h5\", \n",
    "    \"data/exp1/phoebe_2021-05-02_001/spikes.npy\",\n",
    "    \"data/exp1/phoebe_2021-05-03_001/spikes.npy\", \n",
    "    \"data/exp1/phoebe_2021-05-03_001/lfps.h5\", \n",
    "    \"data/exp1/phoebe_2021-05-04_001/spikes.npy\",\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    path.touch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the pathlib library\n",
    "\n",
    "The pathlib module in Python introduces an object-oriented approach to file system paths--. This section is designed to familiarize you with this powerful library, enhancing your ability to handle file paths and directories with more flexibility and intuitiveness. We'll cover basic operations like listing directories, globbing for pattern matching, and more, all through the lens of object-oriented programming.\n",
    "\n",
    "| Command | Purpose |\n",
    "| :-- | :-- |\n",
    "| `from pathlib import Path` | | \n",
    "| `Path.cwd()` | Gets the current working directory. |\n",
    "| `Path('.').resolve()` | Also gets the current working directory. |\n",
    "| `path = Path('./data')` | Make a `Path` object located in the data folder of the working directory. |\n",
    "| `list(path.iterdir())` | List all the files and folders in the specified path |\n",
    "| `new_path = path.joinpath(\"raw\")` | Append the \"/raw\" folder to the current path |\n",
    "| `new_path = path / \"raw\"` | Also append the \"/raw\" folder to the current path. |\n",
    "| `glob.glob('*.h5')` | Search for files that end in \".h5\" in the current path. |\n",
    "| `glob.glob('data*')` | Search for files that start with \"data\" in the current path. |\n",
    "| `glob.glob('./**/data*')` | Search for files that start with \"data\" in the any subfolder in the current path. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the current working directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/NickDG/Projects/remoteDuckDB/draft3')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/NickDG/Projects/remoteDuckDB/draft3')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path('.').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/NickDG/Projects/remoteDuckDB/draft3')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path().resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files and folders are inside the current working directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('1_navigating_filesystems_os_fsspec_objects.ipynb'),\n",
       " WindowsPath('2_parsing_metadata_from_filenames_str_glob.ipynb'),\n",
       " WindowsPath('3_metadata_in_json_arrays_dict.ipynb'),\n",
       " WindowsPath('4_sql_across_json_files_with_duckdb_and_hive.ipynb'),\n",
       " WindowsPath('5_storing_arrays_flat_npy.ipynb'),\n",
       " WindowsPath('6_hdf5.ipynb'),\n",
       " WindowsPath('7_sql_schemas_sql_joins_with_duckdb.ipynb'),\n",
       " WindowsPath('8_pipelines_finalizing_data_into_parquet_files.ipynb'),\n",
       " WindowsPath('data')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path().iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Files and folders are inside the \"data\" directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data\").iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What Files and Folders are inside the \"exp1\" directory, inside the \"data\" directory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-01_001'),\n",
       " WindowsPath('data/exp1/joey_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-04_001')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data/exp1\").iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-01_001'),\n",
       " WindowsPath('data/exp1/joey_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-04_001')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path().joinpath(\"data\").joinpath(\"exp1\").iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What folders in exp1 start with the subject \"phoebe\" (Hint: use Path().glob())?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/phoebe_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-04_001')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data/exp1\").glob(\"phoebe*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What folders in exp1 start with the subject \"joey\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-01_001'),\n",
       " WindowsPath('data/exp1/joey_2021-05-02_001')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data/exp1\").glob(\"joey*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What folders in exp1 were recorded on the 2nd of May (hint-glob on the date part of the filename)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-02_001'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-02_001')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data/exp1\").glob(\"*2021-05-02*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files have the \".h5\" file extension (include all files in any subfolders of exp1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-02_001/lfps.h5'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001/lfps.h5')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data/exp1\").glob(\"**/*.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files have the \".npy\" file extension (include all files in any subfolders of exp1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/joey_2021-05-01_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/joey_2021-05-02_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-02_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-03_001/spikes.npy'),\n",
       " WindowsPath('data/exp1/phoebe_2021-05-04_001/spikes.npy')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data/exp1\").glob(\"**/*.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of phoebe's files contain lfp data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/exp1/phoebe_2021-05-03_001/lfps.h5')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path(\"data/exp1\").glob(\"phoebe*/**/lfps*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Remote File Systems using `fsspec`: \n",
    "\n",
    "In modern neuroscience research, accessing and manipulating data stored in remote file systems is increasingly common. This section introduces fsspec, a library for interacting with various file systems, including remote and cloud-based storage. We'll explore how to list, search, and manage files on different remote systems, an invaluable skill in a data-intensive field like neuroscience.\n",
    "\n",
    "\n",
    "| Code | Description |\n",
    "| :-- | :-- |\n",
    "|`fs.ls()` | Lists all files and directories in the current directory of the filesystem. |\n",
    "| `fs.glob('*.h5')` | Searches for files matching a specified pattern (in this case, all files ending with '.h5') in the current directory and subdirectories. |\n",
    "| `fs.makedirs()` | Creates a new directory at the specified path, including any necessary intermediate directories. |\n",
    "| `fs.removedirs()` | Removes directories recursively. Deletes a directory and, if it's empty, its parent directories as well. |\n",
    "| `fs.rm()` | Removes (deletes) a file or directory. |\n",
    "| `fs.read_text()`| Reads the contents of a file and returns it as a string. |\n",
    "| `fs.read_bytes()` | Reads the contents of a file and returns it as bytes. |\n",
    "| `fs.download()`| Downloads a file from the remote filesystem to the local filesystem. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub Repos as a Remote Filesystem\n",
    "\n",
    "GitHub, a platform widely used for code sharing and collaboration, can also serve as a remote filesystem for data storage and retrieval. This section guides you through using GitHub repositories for accessing and managing data files, leveraging the `GithubFileSystem` class in `fsspec`. \n",
    "\n",
    "```python\n",
    "from fsspec.implementations.github import GithubFileSystem\n",
    "fs = GithubFileSystem(org=\"ibehave-ibots\", repo=\"iBOTS-Tools\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**: Explore navigating remote GitHub filesystems using the `fsspec`'s `GithubFileSystem` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "from fsspec.implementations.github import GithubFileSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files in the root directory of https://github.com/mwaskom/seaborn-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md',\n",
       " 'anagrams.csv',\n",
       " 'anscombe.csv',\n",
       " 'attention.csv',\n",
       " 'brain_networks.csv',\n",
       " 'car_crashes.csv',\n",
       " 'dataset_names.txt',\n",
       " 'diamonds.csv',\n",
       " 'dots.csv',\n",
       " 'dowjones.csv',\n",
       " 'exercise.csv',\n",
       " 'flights.csv',\n",
       " 'fmri.csv',\n",
       " 'geyser.csv',\n",
       " 'glue.csv',\n",
       " 'healthexp.csv',\n",
       " 'iris.csv',\n",
       " 'mpg.csv',\n",
       " 'penguins.csv',\n",
       " 'planets.csv',\n",
       " 'png',\n",
       " 'process',\n",
       " 'raw',\n",
       " 'seaice.csv',\n",
       " 'taxis.csv',\n",
       " 'tips.csv',\n",
       " 'titanic.csv']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = GithubFileSystem(org=\"mwaskom\", repo=\"seaborn-data\")\n",
    "fs.ls(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files whose filenames start with the letter \"p\" (i.e. \"glob\" the files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['penguins.csv', 'planets.csv', 'png', 'process']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.glob(\"p*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files whose filenames end in the \"CSV\" extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anagrams.csv',\n",
       " 'anscombe.csv',\n",
       " 'attention.csv',\n",
       " 'brain_networks.csv',\n",
       " 'car_crashes.csv',\n",
       " 'diamonds.csv',\n",
       " 'dots.csv',\n",
       " 'dowjones.csv',\n",
       " 'exercise.csv',\n",
       " 'flights.csv',\n",
       " 'fmri.csv',\n",
       " 'geyser.csv',\n",
       " 'glue.csv',\n",
       " 'healthexp.csv',\n",
       " 'iris.csv',\n",
       " 'mpg.csv',\n",
       " 'penguins.csv',\n",
       " 'planets.csv',\n",
       " 'seaice.csv',\n",
       " 'taxis.csv',\n",
       " 'tips.csv',\n",
       " 'titanic.csv']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.glob(\"*.csv\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the PNG image files in the \"png\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['png/img1.png',\n",
       " 'png/img2.png',\n",
       " 'png/img3.png',\n",
       " 'png/img4.png',\n",
       " 'png/img5.png',\n",
       " 'png/img6.png']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the PNG image files in the \"png\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.download(\"png/*\", \"data/seaborn-images\")  # note: need glob (has to download files, apparantly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all the files in the root directory of the repo, with `detail=True` (i.e. `fs.ls(\"/\", detail=True)`).  What information does it give us about these files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mode</th>\n",
       "      <th>type</th>\n",
       "      <th>size</th>\n",
       "      <th>sha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>README.md</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>3101</td>\n",
       "      <td>453ab596a15d1f38f2514770783bda43d97ed755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anagrams.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>361</td>\n",
       "      <td>1d88d051b7fff295350bc2ed509b1946d41190b4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anscombe.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>556</td>\n",
       "      <td>62792b68fa5eed40eb75fe00e8daeaaf700f4f82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>1198</td>\n",
       "      <td>8d1f684e36f36aea05b10408c055eb4b30a3fcef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brain_networks.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>1075911</td>\n",
       "      <td>1ca1f474fa81aa8ee01654da5d6c9fd90c96fa27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>car_crashes.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>3301</td>\n",
       "      <td>2248a441bfbbfb1d5c9fa7dbc9dae641c34829a1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset_names.txt</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>174</td>\n",
       "      <td>2a27f085940eba05b41e87bbcc2d8c075c000831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>diamonds.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>2772143</td>\n",
       "      <td>92259b40dbeea3165759a8f2cb576896612828ac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dots.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>25742</td>\n",
       "      <td>9b7eebf50146fd573b055b3b9f8d2caa57879723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dowjones.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>11349</td>\n",
       "      <td>8c35bf1355e823bd2aa119d2f4979c812e898df1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>exercise.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>2735</td>\n",
       "      <td>28a6e946a50375555f67314f86d8d11aa2a4ff17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flights.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>2350</td>\n",
       "      <td>831265b40b19695dd9bd4f7c5bf4baa43c7b54b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fmri.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>38329</td>\n",
       "      <td>5379a9f917d328baff09ff7140e396c44448eaba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>geyser.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>4199</td>\n",
       "      <td>bc7cafc5cf0200b0c92eae896534770fa25bb9f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>glue.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>2054</td>\n",
       "      <td>af5c8c314c8906120ee626f47e830eef42e3745b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>healthexp.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>7222</td>\n",
       "      <td>a0602d1b18e82fb3bb44ddc79c8d9b53458544d5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iris.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>3858</td>\n",
       "      <td>20bd6ee57729baea0cc8b05397cc34eb4af8b452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mpg.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>21222</td>\n",
       "      <td>4013b0f0d4ac5bfb40381819ad76f926962192f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>penguins.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>13478</td>\n",
       "      <td>51fd0fe50c4e01e6f42e54063925571c004ef25a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>planets.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>36263</td>\n",
       "      <td>337318354770d42471fd5ee21acd3deb40956f7c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>png</td>\n",
       "      <td>040000</td>\n",
       "      <td>directory</td>\n",
       "      <td>0</td>\n",
       "      <td>99744314ccef8679fedcf29c33934f30512fd183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>process</td>\n",
       "      <td>040000</td>\n",
       "      <td>directory</td>\n",
       "      <td>0</td>\n",
       "      <td>0015761099c99537288210a92dcef24f34eadddf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>raw</td>\n",
       "      <td>040000</td>\n",
       "      <td>directory</td>\n",
       "      <td>0</td>\n",
       "      <td>f2a72f6b359bc69099e4649eee56a5bb1a252a47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>seaice.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>231046</td>\n",
       "      <td>d68e9028569c8afff3a19fa558a37f245ff92cb2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>taxis.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>869349</td>\n",
       "      <td>ded045b462d361b8a0e5ddcdd6c3361cce4ddab4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>tips.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>9729</td>\n",
       "      <td>1280a10886c1f858b29c1be1740619cdef3d6be1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>titanic.csv</td>\n",
       "      <td>100644</td>\n",
       "      <td>file</td>\n",
       "      <td>57018</td>\n",
       "      <td>5ca531f5d70ce01e61bd7cf8b9f02b016dad4cd0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name    mode       type     size  \\\n",
       "0            README.md  100644       file     3101   \n",
       "1         anagrams.csv  100644       file      361   \n",
       "2         anscombe.csv  100644       file      556   \n",
       "3        attention.csv  100644       file     1198   \n",
       "4   brain_networks.csv  100644       file  1075911   \n",
       "5      car_crashes.csv  100644       file     3301   \n",
       "6    dataset_names.txt  100644       file      174   \n",
       "7         diamonds.csv  100644       file  2772143   \n",
       "8             dots.csv  100644       file    25742   \n",
       "9         dowjones.csv  100644       file    11349   \n",
       "10        exercise.csv  100644       file     2735   \n",
       "11         flights.csv  100644       file     2350   \n",
       "12            fmri.csv  100644       file    38329   \n",
       "13          geyser.csv  100644       file     4199   \n",
       "14            glue.csv  100644       file     2054   \n",
       "15       healthexp.csv  100644       file     7222   \n",
       "16            iris.csv  100644       file     3858   \n",
       "17             mpg.csv  100644       file    21222   \n",
       "18        penguins.csv  100644       file    13478   \n",
       "19         planets.csv  100644       file    36263   \n",
       "20                 png  040000  directory        0   \n",
       "21             process  040000  directory        0   \n",
       "22                 raw  040000  directory        0   \n",
       "23          seaice.csv  100644       file   231046   \n",
       "24           taxis.csv  100644       file   869349   \n",
       "25            tips.csv  100644       file     9729   \n",
       "26         titanic.csv  100644       file    57018   \n",
       "\n",
       "                                         sha  \n",
       "0   453ab596a15d1f38f2514770783bda43d97ed755  \n",
       "1   1d88d051b7fff295350bc2ed509b1946d41190b4  \n",
       "2   62792b68fa5eed40eb75fe00e8daeaaf700f4f82  \n",
       "3   8d1f684e36f36aea05b10408c055eb4b30a3fcef  \n",
       "4   1ca1f474fa81aa8ee01654da5d6c9fd90c96fa27  \n",
       "5   2248a441bfbbfb1d5c9fa7dbc9dae641c34829a1  \n",
       "6   2a27f085940eba05b41e87bbcc2d8c075c000831  \n",
       "7   92259b40dbeea3165759a8f2cb576896612828ac  \n",
       "8   9b7eebf50146fd573b055b3b9f8d2caa57879723  \n",
       "9   8c35bf1355e823bd2aa119d2f4979c812e898df1  \n",
       "10  28a6e946a50375555f67314f86d8d11aa2a4ff17  \n",
       "11  831265b40b19695dd9bd4f7c5bf4baa43c7b54b1  \n",
       "12  5379a9f917d328baff09ff7140e396c44448eaba  \n",
       "13  bc7cafc5cf0200b0c92eae896534770fa25bb9f1  \n",
       "14  af5c8c314c8906120ee626f47e830eef42e3745b  \n",
       "15  a0602d1b18e82fb3bb44ddc79c8d9b53458544d5  \n",
       "16  20bd6ee57729baea0cc8b05397cc34eb4af8b452  \n",
       "17  4013b0f0d4ac5bfb40381819ad76f926962192f1  \n",
       "18  51fd0fe50c4e01e6f42e54063925571c004ef25a  \n",
       "19  337318354770d42471fd5ee21acd3deb40956f7c  \n",
       "20  99744314ccef8679fedcf29c33934f30512fd183  \n",
       "21  0015761099c99537288210a92dcef24f34eadddf  \n",
       "22  f2a72f6b359bc69099e4649eee56a5bb1a252a47  \n",
       "23  d68e9028569c8afff3a19fa558a37f245ff92cb2  \n",
       "24  ded045b462d361b8a0e5ddcdd6c3361cce4ddab4  \n",
       "25  1280a10886c1f858b29c1be1740619cdef3d6be1  \n",
       "26  5ca531f5d70ce01e61bd7cf8b9f02b016dad4cd0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(fs.ls(\"/\", detail=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and print the text contents of the \"anscombe.csv\" file. What data is inside this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\tx\ty\n",
      "I\t10.0\t8.04\n",
      "I\t8.0\t6.95\n",
      "I\t13.0\t7.58\n",
      "I\t9.0\t8.81\n",
      "I\t11.0\t8.33\n",
      "I\t14.0\t9.96\n",
      "I\t6.0\t7.24\n",
      "I\t4.0\t4.26\n",
      "I\t12.0\t10.84\n",
      "I\t7.0\t4.82\n",
      "I\t5.0\t5.68\n",
      "II\t10.0\t9.14\n",
      "II\t8.0\t8.14\n",
      "II\t13.0\t8.74\n",
      "II\t9.0\t8.77\n",
      "II\t11.0\t9.26\n",
      "II\t14.0\t8.1\n",
      "II\t6.0\t6.13\n",
      "II\t4.0\t3.1\n",
      "II\t12.0\t9.13\n",
      "II\t7.0\t7.26\n",
      "II\t5.0\t4.74\n",
      "III\t10.0\t7.46\n",
      "III\t8.0\t6.77\n",
      "III\t13.0\t12.74\n",
      "III\t9.0\t7.11\n",
      "III\t11.0\t7.81\n",
      "III\t14.0\t8.84\n",
      "III\t6.0\t6.08\n",
      "III\t4.0\t5.39\n",
      "III\t12.0\t8.15\n",
      "III\t7.0\t6.42\n",
      "III\t5.0\t5.73\n",
      "IV\t8.0\t6.58\n",
      "IV\t8.0\t5.76\n",
      "IV\t8.0\t7.71\n",
      "IV\t8.0\t8.84\n",
      "IV\t8.0\t8.47\n",
      "IV\t8.0\t7.04\n",
      "IV\t8.0\t5.25\n",
      "IV\t19.0\t12.5\n",
      "IV\t8.0\t5.56\n",
      "IV\t8.0\t7.91\n",
      "IV\t8.0\t6.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fs.read_text(\"/anscombe.csv\").replace(',', '\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DeepLabCut**: Answer the following questions about the DeepLabCut GitHub Repo:   https://github.com/DeepLabCut/DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What files are in the root directory of the DeepLabCut repo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.circleci',\n",
       " '.codespellrc',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " 'AUTHORS',\n",
       " 'CODE_OF_CONDUCT.md',\n",
       " 'CONTRIBUTING.md',\n",
       " 'LICENSE',\n",
       " 'NOTICE.yml',\n",
       " 'README.md',\n",
       " '_config.yml',\n",
       " '_toc.yml',\n",
       " 'conda-environments',\n",
       " 'deeplabcut',\n",
       " 'dlc.py',\n",
       " 'docker',\n",
       " 'docs',\n",
       " 'examples',\n",
       " 'reinstall.sh',\n",
       " 'requirements.txt',\n",
       " 'setup.py',\n",
       " 'tests',\n",
       " 'testscript_cli.py',\n",
       " 'tools']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = GithubFileSystem(org=\"DeepLabCut\", repo=\"DeepLabCut\")\n",
    "fs.ls(\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many files or folders are in the \"openfield-Pranav-2018-10-30\" folder, which is in the \"examples\" folder?  (Tip: the `len()` function can be helpful here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['examples/openfield-Pranav-2018-10-30/config.yaml',\n",
       " 'examples/openfield-Pranav-2018-10-30/labeled-data',\n",
       " 'examples/openfield-Pranav-2018-10-30/videos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.glob(\"examples/open*/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many files are there, if you include every single file or folder in all the subfolders of the openfield example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fs.glob(\"examples/open*/**\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the \"labeled-data\" files in the openfield example (`fs.download(recursive=True)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.download(\"examples/open*/labeled-data\", \"deeplabcut/pranav/labeled-data\", recursive=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duckdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
